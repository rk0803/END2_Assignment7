{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment7_1LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQhOmQONjWFA"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwn5o9Koput0"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiRFox1YN5_u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4cc4f62-6468-4405-b875-0a0c31839835"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3CNF2ewOENt"
      },
      "source": [
        "##Overview of the Stanford Sentiment Analysis Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ohcgUqdqH-m"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "dir_path='/content/drive/MyDrive/stanford'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX4g2KPSOb_h"
      },
      "source": [
        "sentences=pd.read_csv(os.path.join(dir_path,'datasetSentences.txt'),sep='\\t')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYh0RBjFOwZm"
      },
      "source": [
        "### A glimpse of dataset of sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQe6cHDEO6CL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "22056f27-0961-4fb0-b31d-ed4eaca2ab8c"
      },
      "source": [
        "sentences.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_index                                           sentence\n",
              "0               1  The Rock is destined to be the 21st Century 's...\n",
              "1               2  The gorgeously elaborate continuation of `` Th...\n",
              "2               3                     Effective but too-tepid biopic\n",
              "3               4  If you sometimes like to go to the movies to h...\n",
              "4               5  Emerges as something rare , an issue movie tha..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAl7iqKLO9vt"
      },
      "source": [
        "splits=pd.read_csv(os.path.join(dir_path,'datasetSplit.txt'),sep=',')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiQ7yNa6POme"
      },
      "source": [
        "Check if the shape of sentences and splits matches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1OWDPCWPU8G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a52efce-8f00-42bd-ae35-140015e7c3fa"
      },
      "source": [
        "sentences.shape, splits.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11855, 2), (11855, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zNSRjH5PaQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b238091-70b3-4378-8fad-4addad19b54a"
      },
      "source": [
        "sentences.columns, splits.columns"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Index(['sentence_index', 'sentence'], dtype='object'),\n",
              " Index(['sentence_index', 'splitset_label'], dtype='object'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTofdUxnPsIt"
      },
      "source": [
        "Since both sentences and spllits have sentence index, we can join the two on sentence_index, which gives us view of sentences and their split index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s4EHubaPqOp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "186a19f8-7d90-44a8-fb40-31d5c6e6839d"
      },
      "source": [
        "sentence_split_view=sentences.merge(splits,on='sentence_index')\n",
        "sentence_split_view.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>splitset_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_index  ... splitset_label\n",
              "0               1  ...              1\n",
              "1               2  ...              1\n",
              "2               3  ...              2\n",
              "3               4  ...              2\n",
              "4               5  ...              2\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjf5QaPwQaHb"
      },
      "source": [
        "Now lets work out the label of sentences part, from the sentiment values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc69SxhGQguQ"
      },
      "source": [
        "sent_label=pd.read_csv(os.path.join(dir_path,'sentiment_labels.txt'),sep='|', names=['phrase_ids','sentiment_values'])\n",
        "phr=pd.read_csv(os.path.join(dir_path,'dictionary.txt'),sep='|',names=['phrases','phrase_id'],dtype=pd.StringDtype())\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhUMFn0K3nCw",
        "outputId": "cdaff746-3b36-4df7-9b68-f91555453a20"
      },
      "source": [
        "phr.columns"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['phrases', 'phrase_id'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwMYhOJ8VDEs"
      },
      "source": [
        "Now further merge the phrases an sentence_split_view"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6--6DYLVNSx"
      },
      "source": [
        "sent_split_and_phrases=sentence_split_view.merge(phr,left_on='sentence', right_on='phrases',how='left')\n",
        "#Now merge with sent_labels\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaLg8pZv4MU5"
      },
      "source": [
        "sentiDataset=sent_split_and_phrases.merge(sent_label,left_on='phrase_id',right_on='phrase_ids',how='left')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBubzl2sWnZ5"
      },
      "source": [
        "Now discretize the labels from the sentiment values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xCmvqwdWsoK"
      },
      "source": [
        "def label_from_sentiment(x):\n",
        "  if x>=0.0 and x < 0.2:\n",
        "    l=1\n",
        "  elif x>=0.2 and x< 0.4 :\n",
        "    l=2\n",
        "  elif x>=0.4 and x < 0.6:\n",
        "    l=3\n",
        "  elif x>=0.6 and x < 0.8:\n",
        "    l=4\n",
        "  else:\n",
        "    l=5\n",
        "  return str(l)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFISOWWFX0Bn"
      },
      "source": [
        "sentiDataset['labels']= [label_from_sentiment(float(i)) for i in sentiDataset['sentiment_values']]"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwa9OwdaYXuX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "d31063b7-db21-44ec-8a65-9de84e5801be"
      },
      "source": [
        "sentiDataset.head()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>splitset_label</th>\n",
              "      <th>phrases</th>\n",
              "      <th>phrase_id</th>\n",
              "      <th>phrase_ids</th>\n",
              "      <th>sentiment_values</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>226166</td>\n",
              "      <td>226166</td>\n",
              "      <td>0.69444</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>1</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>226300</td>\n",
              "      <td>226300</td>\n",
              "      <td>0.83333</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>2</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>13995</td>\n",
              "      <td>13995</td>\n",
              "      <td>0.51389</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>2</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>14123</td>\n",
              "      <td>14123</td>\n",
              "      <td>0.73611</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>2</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>13999</td>\n",
              "      <td>13999</td>\n",
              "      <td>0.86111</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_index  ... labels\n",
              "0               1  ...      4\n",
              "1               2  ...      5\n",
              "2               3  ...      3\n",
              "3               4  ...      4\n",
              "4               5  ...      5\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG1IAUs9Y4tv"
      },
      "source": [
        "df_senti=(sentiDataset[['sentence','labels']]).reset_index(drop=True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jihzfcfMYwcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4b57ec-982f-4e2e-9f10-bc3c6260bb9a"
      },
      "source": [
        "df_senti.shape\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11855, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6ehSxhX-JMO",
        "outputId": "d87b5200-634f-4154-8dfc-d2552831ca46"
      },
      "source": [
        "df_senti.labels.value_counts()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    2971\n",
              "4    2966\n",
              "5    2342\n",
              "3    2144\n",
              "1    1432\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Oe9tqxkG7tk8",
        "outputId": "1a6e75bf-a271-44ac-d2d4-1f60a8ffc128"
      },
      "source": [
        "df_senti.head()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  labels\n",
              "0  The Rock is destined to be the 21st Century 's...       4\n",
              "1  The gorgeously elaborate continuation of `` Th...       5\n",
              "2                     Effective but too-tepid biopic       3\n",
              "3  If you sometimes like to go to the movies to h...       4\n",
              "4  Emerges as something rare , an issue movie tha...       5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGeIuc-HrtVc"
      },
      "source": [
        "#### Creating the Dataset from the data manipulated earlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDIyapAa6Pjr"
      },
      "source": [
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext import data"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db3eiDVx6mKf"
      },
      "source": [
        "#Review\n",
        "Review_text= torchtext.legacy.data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = torchtext.legacy.data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-by1zHIV7LPI"
      },
      "source": [
        "fields = [('review',Review_text),('label',Label)]"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxmCFTgk797i"
      },
      "source": [
        "data_example = [torchtext.legacy.data.Example.fromlist([df_senti.sentence[i],df_senti.labels[i]], fields) for i in range(df_senti.shape[0])] "
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lj9XCy38OqE"
      },
      "source": [
        "SSTdataset=torchtext.legacy.data.Dataset(data_example,fields)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4BMJcLa8HFX",
        "outputId": "12895318-b97d-4914-e072-432a3abcb7cb"
      },
      "source": [
        "len(SSTdataset)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11855"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C5-VkqVDeB_"
      },
      "source": [
        "import random"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQc3ffEDGrm7"
      },
      "source": [
        "from torch.utils.data.dataset import random_split"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY7gIJQYGk_6"
      },
      "source": [
        "lengths = [int(len(SSTdataset)*0.70), int(len(SSTdataset)*0.30+1)]\n",
        "(train_set, test_set) = random_split(SSTdataset, lengths)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyYk_3FcIS31"
      },
      "source": [
        "train_set=torchtext.legacy.data.Dataset(train_set,fields)\n",
        "test_set=torchtext.legacy.data.Dataset(test_set,fields)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZVfuVj0pFiR",
        "outputId": "08d18594-2b84-40ae-b647-ddd631c6e6ed"
      },
      "source": [
        "len(train_set),len(test_set)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8298, 3557)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mfQdgoAtTg8"
      },
      "source": [
        "Review_text.build_vocab(train_set)\n",
        "Label.build_vocab(train_set)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCPG8VrE9MKq",
        "outputId": "bf9e6329-2529-4cb0-e684-c10a02efb390"
      },
      "source": [
        "print('Size of input vocab : ', len(Review_text.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Review_text.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  16987\n",
            "Size of label vocab :  5\n",
            "Top 10 words appreared repeatedly : [('.', 7819), (',', 7019), ('the', 5902), ('and', 4368), ('a', 4298), ('of', 4261), ('to', 2984), ('-', 2663), ('is', 2478), (\"'s\", 2467)]\n",
            "Labels :  defaultdict(None, {2: 0, 4: 1, 5: 2, 3: 3, 1: 4})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBmMQQcX9SZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c885d59-c04b-4e09-fbd1-bc929118be95"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4mL1dn1TCDQ"
      },
      "source": [
        "Creating the iterators from the datasets (train_set and test_set created)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL5VTWKGuN0z"
      },
      "source": [
        "train_iterator = torchtext.legacy.data.BucketIterator(train_set, batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.review),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8_AHscmvsps"
      },
      "source": [
        "test_iterator = torchtext.legacy.data.BucketIterator(test_set, batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.review),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU0AI7eOSj4m"
      },
      "source": [
        "Dumping the vocabulary to be used later for predicting labels for new reviews  or from validation set (not created and used here)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_NVSpoV-Uaj"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    #pickle.dump(Tweet.vocab.stoi, tokens)\n",
        "    pickle.dump(Review_text.vocab.stoi,tokens)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNQnNcH6-oZZ"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "            \n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        # packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.encoder(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "        # Hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs = self.fc(hidden)   \n",
        "        \n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\n",
        "            \n",
        "        return output"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFNWimMMAKya"
      },
      "source": [
        "# Define hyperparameters\n",
        "#size_of_vocab = len(Tweet.vocab)\n",
        "size_of_vocab=len(Review_text.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 100\n",
        "num_output_nodes = 5\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRextCcAASGO",
        "outputId": "17a7d9b2-e5c2-4536-becb-1ad2442ae772"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(16987, 300)\n",
            "  (encoder): LSTM(300, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  (fc): Linear(in_features=100, out_features=5, bias=True)\n",
            ")\n",
            "The model has 5,338,205 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9sAGdpme3Pz",
        "outputId": "0f8c6529-5b6c-40cf-c3ef-9e448896fed0"
      },
      "source": [
        "device"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPK6b19HATLm"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RU2ZepENlXt"
      },
      "source": [
        "Pls ignore next few cells till train funtion. These are my trails and learnings.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6du_y2GysnL"
      },
      "source": [
        "optimizer.zero_grad()  \n",
        "review,review_length = b.review\n",
        "predictions=model(review,review_length)"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1m9mL9RzqWd"
      },
      "source": [
        "predictions.shape, b.label.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo2TNJlUz9S2"
      },
      "source": [
        "predictions[0][2],\n",
        "b.label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EDTeY_Jlbca"
      },
      "source": [
        "loss = criterion(predictions, b.label)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JahjP_yNll7R",
        "outputId": "e2ba5c10-4dc0-479e-f702-974d75ef8d0d"
      },
      "source": [
        "loss.item()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.6094882488250732"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RtfQalJlrQl"
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSgMyAGXlwdX"
      },
      "source": [
        " optimizer.step()  "
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEzQTy05l-_X",
        "outputId": "e30d12e6-caf4-4aed-ce4c-4bfb23e47459"
      },
      "source": [
        "optimizer.zero_grad()  \n",
        "review,review_length = b.review\n",
        "predictions=model(review,review_length)\n",
        "loss = criterion(predictions, b.label)\n",
        "print(loss.item())\n",
        "loss.backward()\n",
        "optimizer.step()"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6056932210922241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8t9iWwqAify"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        #tweet, tweet_lengths = batch.tweet  \n",
        "        review,review_length = batch.review\n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        #predictions = model(tweet, tweet_lengths).squeeze()  \n",
        "        predictions=model(review,review_length)\n",
        "        \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        L2_lambda=0.001\n",
        "        L2_norm=sum(p.pow(2.0).sum() for p in model.parameters())    \n",
        "        loss=loss+L2_lambda*L2_norm\n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.label)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMBXHd5JAuX-"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            #tweet, tweet_lengths = batch.tweet\n",
        "            review,review_length = batch.review\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(review, review_length).squeeze()\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            L2_lambda=0.001\n",
        "            L2_norm=sum(p.pow(2.0).sum() for p in model.parameters())    \n",
        "            loss=loss+L2_lambda*L2_norm\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1gReGGkegAL"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viVu0fdv0wJd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')\n",
        "import numpy as np"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7UPwN0KAvVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab4ae85-15b6-4327-a565-50398d8a6ca3"
      },
      "source": [
        "N_EPOCHS = 50\n",
        "best_test_loss = float('inf')\n",
        "best_test_acc=float(0.0)\n",
        "global plot_iter, plot_loss_train, plot_loss_val\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss_train = np.zeros((0))\n",
        "plot_loss_test = np.zeros((0))\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if  (test_acc > best_test_acc):\n",
        "        best_test_loss = test_loss\n",
        "        best_test_acc = test_acc\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\t epoch : {epoch} |\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Test Loss: {test_loss:.3f} |  Test. Acc: {test_acc*100:.2f}% \\n')\n",
        "    plot_iter = np.append(plot_iter, [epoch])\n",
        "    plot_loss_train = np.append(plot_loss_train, [train_loss])\n",
        "    plot_loss_test = np.append(plot_loss_test, [test_loss])\n",
        "print(f'\\t Best Test Loss: {best_test_loss:.3f} |  Best Test. Acc: {best_test_acc*100:.2f}% \\n')"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t epoch : 0 |\tTrain Loss: 4893.060 | Train Acc: 25.50%\n",
            "\t Test Loss: 4693.010 |  Test. Acc: 25.76% \n",
            "\n",
            "\t epoch : 1 |\tTrain Loss: 4506.197 | Train Acc: 27.12%\n",
            "\t Test Loss: 4323.397 |  Test. Acc: 27.65% \n",
            "\n",
            "\t epoch : 2 |\tTrain Loss: 4152.096 | Train Acc: 28.31%\n",
            "\t Test Loss: 3984.249 |  Test. Acc: 28.22% \n",
            "\n",
            "\t epoch : 3 |\tTrain Loss: 3826.605 | Train Acc: 30.90%\n",
            "\t Test Loss: 3671.991 |  Test. Acc: 31.65% \n",
            "\n",
            "\t epoch : 4 |\tTrain Loss: 3526.549 | Train Acc: 35.07%\n",
            "\t Test Loss: 3383.820 |  Test. Acc: 34.12% \n",
            "\n",
            "\t epoch : 5 |\tTrain Loss: 3249.382 | Train Acc: 37.98%\n",
            "\t Test Loss: 3117.401 |  Test. Acc: 35.33% \n",
            "\n",
            "\t epoch : 6 |\tTrain Loss: 2992.961 | Train Acc: 39.10%\n",
            "\t Test Loss: 2870.756 |  Test. Acc: 36.28% \n",
            "\n",
            "\t epoch : 7 |\tTrain Loss: 2755.448 | Train Acc: 40.19%\n",
            "\t Test Loss: 2642.193 |  Test. Acc: 35.64% \n",
            "\n",
            "\t epoch : 8 |\tTrain Loss: 2535.256 | Train Acc: 41.57%\n",
            "\t Test Loss: 2430.225 |  Test. Acc: 36.61% \n",
            "\n",
            "\t epoch : 9 |\tTrain Loss: 2331.016 | Train Acc: 41.92%\n",
            "\t Test Loss: 2233.582 |  Test. Acc: 36.44% \n",
            "\n",
            "\t epoch : 10 |\tTrain Loss: 2141.512 | Train Acc: 42.52%\n",
            "\t Test Loss: 2051.112 |  Test. Acc: 36.20% \n",
            "\n",
            "\t epoch : 11 |\tTrain Loss: 1965.673 | Train Acc: 43.13%\n",
            "\t Test Loss: 1881.800 |  Test. Acc: 36.10% \n",
            "\n",
            "\t epoch : 12 |\tTrain Loss: 1802.536 | Train Acc: 43.44%\n",
            "\t Test Loss: 1724.744 |  Test. Acc: 36.55% \n",
            "\n",
            "\t epoch : 13 |\tTrain Loss: 1651.235 | Train Acc: 44.03%\n",
            "\t Test Loss: 1579.114 |  Test. Acc: 36.92% \n",
            "\n",
            "\t epoch : 14 |\tTrain Loss: 1510.980 | Train Acc: 44.20%\n",
            "\t Test Loss: 1444.158 |  Test. Acc: 37.01% \n",
            "\n",
            "\t epoch : 15 |\tTrain Loss: 1381.051 | Train Acc: 44.35%\n",
            "\t Test Loss: 1319.187 |  Test. Acc: 36.87% \n",
            "\n",
            "\t epoch : 16 |\tTrain Loss: 1260.777 | Train Acc: 44.91%\n",
            "\t Test Loss: 1203.563 |  Test. Acc: 36.02% \n",
            "\n",
            "\t epoch : 17 |\tTrain Loss: 1149.549 | Train Acc: 44.97%\n",
            "\t Test Loss: 1096.664 |  Test. Acc: 36.99% \n",
            "\n",
            "\t epoch : 18 |\tTrain Loss: 1046.787 | Train Acc: 45.03%\n",
            "\t Test Loss: 997.978 |  Test. Acc: 36.51% \n",
            "\n",
            "\t epoch : 19 |\tTrain Loss: 951.953 | Train Acc: 45.29%\n",
            "\t Test Loss: 906.954 |  Test. Acc: 36.52% \n",
            "\n",
            "\t epoch : 20 |\tTrain Loss: 864.534 | Train Acc: 45.79%\n",
            "\t Test Loss: 823.094 |  Test. Acc: 36.84% \n",
            "\n",
            "\t epoch : 21 |\tTrain Loss: 784.059 | Train Acc: 45.91%\n",
            "\t Test Loss: 745.957 |  Test. Acc: 36.08% \n",
            "\n",
            "\t epoch : 22 |\tTrain Loss: 710.068 | Train Acc: 46.36%\n",
            "\t Test Loss: 675.079 |  Test. Acc: 36.69% \n",
            "\n",
            "\t epoch : 23 |\tTrain Loss: 642.142 | Train Acc: 46.73%\n",
            "\t Test Loss: 610.061 |  Test. Acc: 36.55% \n",
            "\n",
            "\t epoch : 24 |\tTrain Loss: 579.873 | Train Acc: 46.79%\n",
            "\t Test Loss: 550.502 |  Test. Acc: 35.58% \n",
            "\n",
            "\t epoch : 25 |\tTrain Loss: 522.867 | Train Acc: 47.16%\n",
            "\t Test Loss: 496.020 |  Test. Acc: 36.08% \n",
            "\n",
            "\t epoch : 26 |\tTrain Loss: 470.767 | Train Acc: 47.49%\n",
            "\t Test Loss: 446.271 |  Test. Acc: 35.73% \n",
            "\n",
            "\t epoch : 27 |\tTrain Loss: 423.234 | Train Acc: 47.40%\n",
            "\t Test Loss: 400.915 |  Test. Acc: 36.47% \n",
            "\n",
            "\t epoch : 28 |\tTrain Loss: 379.931 | Train Acc: 48.01%\n",
            "\t Test Loss: 359.631 |  Test. Acc: 35.96% \n",
            "\n",
            "\t epoch : 29 |\tTrain Loss: 340.541 | Train Acc: 48.01%\n",
            "\t Test Loss: 322.115 |  Test. Acc: 35.55% \n",
            "\n",
            "\t epoch : 30 |\tTrain Loss: 304.765 | Train Acc: 48.97%\n",
            "\t Test Loss: 288.066 |  Test. Acc: 35.80% \n",
            "\n",
            "\t epoch : 31 |\tTrain Loss: 272.334 | Train Acc: 49.21%\n",
            "\t Test Loss: 257.221 |  Test. Acc: 36.09% \n",
            "\n",
            "\t epoch : 32 |\tTrain Loss: 242.981 | Train Acc: 49.25%\n",
            "\t Test Loss: 229.330 |  Test. Acc: 35.99% \n",
            "\n",
            "\t epoch : 33 |\tTrain Loss: 216.467 | Train Acc: 49.06%\n",
            "\t Test Loss: 204.178 |  Test. Acc: 35.02% \n",
            "\n",
            "\t epoch : 34 |\tTrain Loss: 192.563 | Train Acc: 49.10%\n",
            "\t Test Loss: 181.487 |  Test. Acc: 36.31% \n",
            "\n",
            "\t epoch : 35 |\tTrain Loss: 171.032 | Train Acc: 49.86%\n",
            "\t Test Loss: 161.101 |  Test. Acc: 35.68% \n",
            "\n",
            "\t epoch : 36 |\tTrain Loss: 151.682 | Train Acc: 50.27%\n",
            "\t Test Loss: 142.778 |  Test. Acc: 36.46% \n",
            "\n",
            "\t epoch : 37 |\tTrain Loss: 134.326 | Train Acc: 50.35%\n",
            "\t Test Loss: 126.360 |  Test. Acc: 36.45% \n",
            "\n",
            "\t epoch : 38 |\tTrain Loss: 118.780 | Train Acc: 51.00%\n",
            "\t Test Loss: 111.665 |  Test. Acc: 37.70% \n",
            "\n",
            "\t epoch : 39 |\tTrain Loss: 104.892 | Train Acc: 50.78%\n",
            "\t Test Loss: 98.560 |  Test. Acc: 37.20% \n",
            "\n",
            "\t epoch : 40 |\tTrain Loss: 92.504 | Train Acc: 51.36%\n",
            "\t Test Loss: 86.881 |  Test. Acc: 37.35% \n",
            "\n",
            "\t epoch : 41 |\tTrain Loss: 81.471 | Train Acc: 51.65%\n",
            "\t Test Loss: 76.475 |  Test. Acc: 38.39% \n",
            "\n",
            "\t epoch : 42 |\tTrain Loss: 71.665 | Train Acc: 52.34%\n",
            "\t Test Loss: 67.249 |  Test. Acc: 37.83% \n",
            "\n",
            "\t epoch : 43 |\tTrain Loss: 62.956 | Train Acc: 53.35%\n",
            "\t Test Loss: 59.057 |  Test. Acc: 38.64% \n",
            "\n",
            "\t epoch : 44 |\tTrain Loss: 55.246 | Train Acc: 53.76%\n",
            "\t Test Loss: 51.818 |  Test. Acc: 39.07% \n",
            "\n",
            "\t epoch : 45 |\tTrain Loss: 48.426 | Train Acc: 54.31%\n",
            "\t Test Loss: 45.442 |  Test. Acc: 35.56% \n",
            "\n",
            "\t epoch : 46 |\tTrain Loss: 42.445 | Train Acc: 51.60%\n",
            "\t Test Loss: 39.774 |  Test. Acc: 39.55% \n",
            "\n",
            "\t epoch : 47 |\tTrain Loss: 37.118 | Train Acc: 54.96%\n",
            "\t Test Loss: 34.816 |  Test. Acc: 38.56% \n",
            "\n",
            "\t epoch : 48 |\tTrain Loss: 32.455 | Train Acc: 55.71%\n",
            "\t Test Loss: 30.444 |  Test. Acc: 40.56% \n",
            "\n",
            "\t epoch : 49 |\tTrain Loss: 28.368 | Train Acc: 55.57%\n",
            "\t Test Loss: 26.633 |  Test. Acc: 38.34% \n",
            "\n",
            "\t Best Test Loss: 30.444 |  Best Test. Acc: 40.56% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpTgZT59JxXu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU0-VTlt-DXn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "e6d2b904-20bc-4911-ef95-8b5ef5abef34"
      },
      "source": [
        "plt.plot(plot_iter, plot_loss_train, plot_loss_test)\n",
        "display.clear_output(wait=True)\n",
        "plt.show()"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXCGxks4AxT3"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_review(t):\n",
        "    \n",
        "    categories = {0: \"Positive\",1:\"Negative\", 2:\"Neutral\", 3:\"Very Positive\", 4:\"Very Negative\"}\n",
        "    \n",
        "  \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(t)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        "    #print(prediction)\n",
        "    #print(prediction.max())\n",
        "    #print(categories)\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    #print(pred.item()) \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1mmb9YiHWOv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "02c6ff7d-6d99-479e-e4d2-4f4d6e42b23a"
      },
      "source": [
        "classify_review(\"never buy this product.\")"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Very Positive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKiNMGHVQuh5"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "xiWPaPDZu15M",
        "outputId": "e9815115-470a-46fc-8410-77e8d3889132"
      },
      "source": [
        "uploaded=files.upload()"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f8a56b47-d5e0-4f2f-bba1-b7c495ba0474\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f8a56b47-d5e0-4f2f-bba1-b7c495ba0474\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test_sent.pkl to test_sent.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jSvswtqvFNm"
      },
      "source": [
        "f1=open('test_sent.pkl','rb')\n",
        "tst=pickle.load(f1)\n",
        "f1.close()"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OPXXBxYvSTD"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "np.random.seed(43)"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1DPiYINQngy",
        "outputId": "1ac33948-af95-4795-dc07-f6c038b52e9c"
      },
      "source": [
        "for i in range(10):\n",
        "  r_n=random.choice(tst)\n",
        "  p=classify_review(r_n)\n",
        "  print(f'{r_n} | sentiment : {p}')"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For a shoot - 'em - up , Ballistic is oddly lifeless . | sentiment : Positive\n",
            "( Howard ) so good as Leon Barlow ... that he hardly seems to be acting . | sentiment : Negative\n",
            "It has the courage to wonder about big questions with sincerity and devotion . | sentiment : Negative\n",
            "The stupidest , most insulting movie of 2002 's first quarter . | sentiment : Positive\n",
            "Marvelous , merry and , yes , melancholy film . | sentiment : Neutral\n",
            "However , it lacks grandeur and that epic quality often associated with Stevenson 's tale as well as with earlier Disney efforts . | sentiment : Positive\n",
            "Its save-the-planet message clashes with its crass marketing . | sentiment : Positive\n",
            "Run , do n't walk , to see this barbed and bracing comedy on the big screen . | sentiment : Neutral\n",
            "This is one of Polanski 's best films . | sentiment : Neutral\n",
            "Must-see viewing for anyone involved in the high-tech industry . | sentiment : Neutral\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}